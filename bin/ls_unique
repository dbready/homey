#!/usr/bin/env python

# Print list of unique files as defined by filesize + file hash (currently using blake2b)

import argparse
from collections import defaultdict
import hashlib
import os


def get_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Print the first found file with unique contents (defined by file blake2b hash) recursively under the src directory"
    )
    parser.add_argument("src", default=".", nargs="?")
    return parser.parse_args()


def hash_filename(filename: str) -> str:
    # algorithm choice arbitrary, but supposedly fast based on internet stranger
    hasher = hashlib.blake2b()
    with open(filename, "rb") as handle:
        chunk = handle.read(8192)
        while chunk:
            hasher.update(chunk)
            chunk = handle.read(8192)
    return hasher.hexdigest()


def get_file_collection(src_dir: str):
    observed = defaultdict(list)
    for path, dirs, fnames in os.walk(src_dir):
        # sorting the filenames, but unsure if os.walk has deterministic order
        # which would result in random directory traversal
        for fname in sorted(fnames):
            filename = os.path.normpath(os.path.join(path, fname))
            fsize = os.path.getsize(filename)
            observed[fsize].append(filename)
    return observed


def main(src):
    file_collection = get_file_collection(src)
    for filenames in file_collection.values():
        if len(filenames) == 1:
            print(filenames[0])
        else:
            uniques = set()
            # sorting may not be needed, depending on os.walk behavior
            for filename in sorted(filenames):
                the_hash = hash_filename(filename)
                if the_hash not in uniques:
                    uniques.add(the_hash)
                    print(filename)


if __name__ == "__main__":
    args = get_args()
    src = os.path.normpath(args.src)
    main(src)
